Im Rahmen des Praktikums wurden mehrere Themenbereiche aus der Informatik sowie Mathematik behandelt. \par
Das erste Projekt lies uns erste Erfahrungen mit OpenMP sammeln, indem die nicht deterministische Reihenfolge der Threadausführung gezeigt wurde. Daraufhin wurden Testtools (Intel Thread Checker und OpenMP Profiler) eingeführt, damit wir unsere Programme auf Fehler untersuchen können. Nach diesen ersten Schritten sollten wir uns Gedanken über Maße der parallelen Ausführung machen, welches uns zu mehreren quantitativen Maßzahlen im Kontext von Parallelrechner geleitet hat. Zeitgleich sollten wir uns andere Architekturen und Beschleuniger anschauen und über ihre Vor- und Nachteile diskutieren. Des weiteren wurden typische Fehler wie etwa Verklemmungen und Wettlaufsituationen betrachtet und unter welchen Bedingungen diese eintreten können. \\
Als nächstes sollte dann ein erstes Verfahren, das Gauß-Seidel-Verfahren, sequentiell implementiert werden, um es dann zu parallelisieren mithilfe des angeeigneten Wissen der vorherigen Aufgaben. Zusätzlich war es noch nötig eine geeignete Parallelisierungsmethodik zu finden um eine hohe Beschleunigung trotz Datenabhängigkeiten zu erreichen. \\
Daraufhin wurde unser parallelisiertes Verfahren zur Lösung einer partiellen Differentialgleichung eingesetzt. Hier wurde die Methode der Finiten Differenzen eingesetzt, um das Problem in uniforme Teile zu zerlegen. Diese Zerlegung nimmt einen Parameter entgegen um so die Feinheit der Unterteilung festzulegen. Dies erlaubt Unterschiede in benötigter Rechenzeit und maximalen Berechnungsfehler zu beobachten. \\
Als letzter Aspekt für das erste Projekt wurde aus mehrere Krylow-Unterraumverfahren das CG-Verfahren ausgesucht und implementiert. Dieses sollte das gleiche Problem wie auch schon vorher das Gauß-Seidel-Verfahren lösen, aber mit der Erwartung dass es schneller zum gewünschten Resultat kommt, welches sich bestätigt hat. \par
Das zweite Projekt hatte das Hauptaugenmerk nicht mehr auf der CPU als Hauptrecheneinheit, sondern die GPU, welches wir mit Hilfe von CUDA programmieren konnten. \\
Erste Aufgaben waren das Auslesen der Architekturinformation von den verfügbaren Beschleuniger und die verschiedenen Datentransferraten zu ermitteln. \\
Die vorherigen Programme wurde dann auch noch für eine Ausführung auf der GPU angepasst. Der daraus entstandene Geschwindigkeitszuwachs verglichen zur CPU-Ausführung wurde dann nochmals durch eine breit ausgelegte Literaturrecherche verbessert. Im Allgemeinen wird versucht an einigen Stellen etwas an Genauigkeit einzusparen um somit eine erheblich höhere Geschwindigkeit zu erreichen. Wir haben eine Technik ausgewählt und diese auf unseren Programmen angewendet. Diese Resultate ließen dann Rückschlüsse über die interne Struktur der CPU führen. Zeitgleich hat dies unsere Ausführungszeit bei hoher Auflösung sehr stark verbessert. \\
Des weiterem wurde das Konzept der Vorkonditionierung anhand von zwei gegebenen Algorithmen eingeführt. Diese sollten kurz aus Sicht der Mathematik analysiert werden, welches Informationen zu Vor- und Nachteilen in der Paralleliserbarkeit und Stabilität geliefert hat. \\
Mit allen Bausteinen des Praktikums sollte dann zuletzt ein vollständiges Programm entstehen, welches das Poisson-Gleichung aus dem ersten Projekt löst mit einem gegebenen maximalen Fehler. Durch die vielen einzelnen Stellen an welchen der tolerierte Fehler eingestellt werden konnt, war es uns möglich ein schnelles Programm zu entwickeln welches Einsichten in den Einfluss der verschiedenen Teile des Programm geliefert hat. \par
Das Praktikum hat uns vieles über numerische Aspekte gelehrt, als auch welches Techniken zur Parallelisierung von Programmen genutzt werden. 